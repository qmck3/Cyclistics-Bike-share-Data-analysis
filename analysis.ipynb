{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe65950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0a995",
   "metadata": {},
   "source": [
    "#### Reading data \n",
    "First, I read data from 12 csv files, corresponding to data from 12 months <br>\n",
    "I change 2 fields started_at and ended_at to their corresponding format - datetime <br>\n",
    "And then combine them into 1 dataframe called df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7232d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5779379 entries, 0 to 5779378\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             object        \n",
      " 1   rideable_type       object        \n",
      " 2   started_at          datetime64[ns]\n",
      " 3   ended_at            datetime64[ns]\n",
      " 4   start_station_name  object        \n",
      " 5   start_station_id    object        \n",
      " 6   end_station_name    object        \n",
      " 7   end_station_id      object        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       object        \n",
      "dtypes: datetime64[ns](2), float64(4), object(7)\n",
      "memory usage: 573.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "csv_files = ['202207-divvy-tripdata.csv', '202208-divvy-tripdata.csv','202209-divvy-publictripdata.csv', \n",
    "             '202210-divvy-tripdata.csv', '202211-divvy-tripdata.csv', '202212-divvy-tripdata.csv', \n",
    "             '202301-divvy-tripdata.csv', '202302-divvy-tripdata.csv', '202303-divvy-tripdata.csv', \n",
    "             '202304-divvy-tripdata.csv', '202305-divvy-tripdata.csv', '202306-divvy-tripdata.csv']\n",
    "\n",
    "dfs = []\n",
    "for filename in csv_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df[['started_at', 'ended_at']] = df[['started_at', 'ended_at']].apply(pd.to_datetime)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbed9b9",
   "metadata": {},
   "source": [
    "#### Processing\n",
    "To process data, I delete rows that have NaN values, duplicated rows and rows that have started time equals or larger than ended time <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7ed7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop(df[df.started_at >= df.ended_at].index)\n",
    "df['ride_length'] = df['ended_at'] - df['started_at']\n",
    "df['start_weekday'] = df['started_at'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c825e0",
   "metadata": {},
   "source": [
    "To remove outliers, I apply Empirical rule and drop rows that lay out 3 standard deviation range from mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dacff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:36:59.850994962\n",
      "0 days 02:07:04.000579893\n",
      "-1 days +22:25:04.894610121\n"
     ]
    }
   ],
   "source": [
    "standard_deviation = df['ride_length'].std()\n",
    "mean_ride_len = df['ride_length'].mean()\n",
    "upper_bound = mean_ride_len + standard_deviation * 3\n",
    "lower_bound = mean_ride_len - standard_deviation * 3\n",
    "print(standard_deviation)\n",
    "print(upper_bound)\n",
    "print(lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f688c7c",
   "metadata": {},
   "source": [
    "Since we can only use positive values for time, we don't use lower-bound to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07dcaade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ride_id rideable_type          started_at            ended_at  \\\n",
      "0  954144C2F67B1932  classic_bike 2022-07-05 08:12:47 2022-07-05 08:24:32   \n",
      "1  292E027607D218B6  classic_bike 2022-07-26 12:53:38 2022-07-26 12:55:31   \n",
      "2  57765852588AD6E0  classic_bike 2022-07-03 13:58:49 2022-07-03 14:06:32   \n",
      "3  B5B6BE44314590E6  classic_bike 2022-07-31 17:44:21 2022-07-31 18:42:50   \n",
      "4  A4C331F2A00E79E0  classic_bike 2022-07-13 19:49:06 2022-07-13 20:15:24   \n",
      "\n",
      "           start_station_name start_station_id  \\\n",
      "0  Ashland Ave & Blackhawk St            13224   \n",
      "1  Buckingham Fountain (Temp)            15541   \n",
      "2  Buckingham Fountain (Temp)            15541   \n",
      "3  Buckingham Fountain (Temp)            15541   \n",
      "4      Wabash Ave & Grand Ave     TA1307000117   \n",
      "\n",
      "                 end_station_name end_station_id  start_lat  start_lng  \\\n",
      "0        Kingsbury St & Kinzie St   KA1503000043  41.907066 -87.667252   \n",
      "1           Michigan Ave & 8th St            623  41.869621 -87.623981   \n",
      "2           Michigan Ave & 8th St            623  41.869621 -87.623981   \n",
      "3          Woodlawn Ave & 55th St   TA1307000164  41.869621 -87.623981   \n",
      "4  Sheffield Ave & Wellington Ave   TA1307000052  41.891466 -87.626761   \n",
      "\n",
      "     end_lat    end_lng member_casual     ride_length start_weekday  \n",
      "0  41.889177 -87.638506        member 0 days 00:11:45       Tuesday  \n",
      "1  41.872773 -87.623981        casual 0 days 00:01:53       Tuesday  \n",
      "2  41.872773 -87.623981        casual 0 days 00:07:43        Sunday  \n",
      "3  41.795264 -87.596471        casual 0 days 00:58:29        Sunday  \n",
      "4  41.936253 -87.652662        member 0 days 00:26:18     Wednesday  \n",
      "(4376245, 15)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(df[df['ride_length'] > upper_bound].index)\n",
    "print(df.head(5))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf110f62",
   "metadata": {},
   "source": [
    "#### Analyzing data\n",
    "First, I divide df to 2 sub dataframe of member and casual customers to get some statistics like total rides, total ride length, average and standard deviation of ride time in each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c45ae19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                      2726023\n",
      "mean     0 days 00:11:40.134662473\n",
      "std      0 days 00:10:14.781596613\n",
      "min                0 days 00:00:01\n",
      "25%                0 days 00:05:01\n",
      "50%                0 days 00:08:42\n",
      "75%                0 days 00:14:53\n",
      "max                0 days 02:07:01\n",
      "Name: ride_length, dtype: object\n",
      "count                      1650222\n",
      "mean     0 days 00:19:14.679873374\n",
      "std      0 days 00:19:31.489456068\n",
      "min                0 days 00:00:01\n",
      "25%                0 days 00:07:13\n",
      "50%                0 days 00:12:42\n",
      "75%                0 days 00:23:20\n",
      "max                0 days 02:07:04\n",
      "Name: ride_length, dtype: object\n",
      "count                      4376245\n",
      "mean     0 days 00:14:31.537430605\n",
      "std      0 days 00:14:55.250770576\n",
      "min                0 days 00:00:01\n",
      "25%                0 days 00:05:44\n",
      "50%                0 days 00:10:00\n",
      "75%                0 days 00:17:40\n",
      "max                0 days 02:07:04\n",
      "Name: ride_length, dtype: object\n",
      "member: 1908583193.0\n",
      "casual: 1905478130.0\n"
     ]
    }
   ],
   "source": [
    "member_df = df.loc[df['member_casual'] == 'member']\n",
    "casual_df = df.loc[df['member_casual'] == 'casual']\n",
    "print(member_df.ride_length.describe())\n",
    "print(casual_df.ride_length.describe())\n",
    "print(df.ride_length.describe())\n",
    "print('member:', member_df['ride_length'].dt.total_seconds().sum())\n",
    "print('casual:', casual_df['ride_length'].dt.total_seconds().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0af062",
   "metadata": {},
   "source": [
    "Then I create a dataframe which querry month, type of bike, type of member, and calculate average ride time and count of each observation.<br>\n",
    "And then save it to a excel sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e36c067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  rideable_type member_casual  count  average ride length(s)\n",
      "0      1   classic_bike        casual  13684              789.100628\n",
      "1      1   classic_bike        member  76267              602.018920\n",
      "2      1    docked_bike        casual   1611             1345.608318\n",
      "3      1  electric_bike        casual  14068              579.808573\n",
      "4      1  electric_bike        member  42230              507.729600\n",
      "(60, 5)\n"
     ]
    }
   ],
   "source": [
    "df['month'] = df.loc[:,'started_at'].dt.month\n",
    "month_count= df.groupby(['month','rideable_type','member_casual']).size()\n",
    "month_count = month_count.reset_index(name='count')\n",
    "avg_ride_len = df.groupby(['month','rideable_type','member_casual']).ride_length.mean().dt.total_seconds()\n",
    "avg_ride_len = avg_ride_len.reset_index(name='average ride length(s)')\n",
    "\n",
    "month_df = pd.merge(month_count, avg_ride_len, on = ['member_casual', 'rideable_type', 'month'])\n",
    "#month_df['average ride length'] = month_df['average ride length'].apply(lambda x: str(x).split('.')[0])\n",
    "#month_df['average ride length'] = month_df['average ride length'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "print(month_df.head(5))\n",
    "print(month_df.shape)\n",
    "with pd.ExcelWriter('cyclistics_data.xlsx', mode = 'a', if_sheet_exists='replace') as writer:\n",
    "    month_df.to_excel(writer, sheet_name='bike_type_month', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820497f",
   "metadata": {},
   "source": [
    "Then I create a dataframe which querry hour, weekday, type of member, and calculate average ride time and count of each observation.<br>\n",
    "And then save the data to a excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e651568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hour start_weekday member_casual  count  average ride length(s)\n",
      "0     0        Friday        casual   3578              862.206260\n",
      "1     0        Friday        member   3339              629.187781\n",
      "2     0        Monday        casual   2369             1038.304348\n",
      "3     0        Monday        member   2004              679.911178\n",
      "4     0      Saturday        casual   8156              920.457700\n",
      "(336, 5)\n"
     ]
    }
   ],
   "source": [
    "df['hour'] = df.loc[:,'started_at'].dt.hour\n",
    "customer_hour = df.groupby(['hour', 'start_weekday','member_casual']).size()\n",
    "customer_hour = customer_hour.reset_index(name='count')\n",
    "customer_hour['hour'] = customer_hour['hour'].astype(int)\n",
    "avg_ride_len = df.groupby(['hour', 'start_weekday','member_casual']).ride_length.mean().dt.total_seconds()\n",
    "avg_ride_len = avg_ride_len.reset_index(name='average ride length(s)')\n",
    "\n",
    "customer_hour = pd.merge(customer_hour, avg_ride_len, on = ['hour', 'start_weekday','member_casual'])\n",
    "\n",
    "print(customer_hour.head(5))\n",
    "print(customer_hour.shape)\n",
    "with pd.ExcelWriter('cyclistics_data.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    customer_hour.to_excel(writer, sheet_name='hour_weekday', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0cb03",
   "metadata": {},
   "source": [
    "Then I find top 50 stations that have the most rides from casual customers, these stations may be good for promoting membership advertisement so casual customers can see membership upgrading plans and membership benefits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a45f8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   start_station_name  count\n",
      "0             Streeter Dr & Grand Ave  48615\n",
      "1   DuSable Lake Shore Dr & Monroe St  28496\n",
      "2               Michigan Ave & Oak St  21820\n",
      "3                     Millennium Park  21139\n",
      "4  DuSable Lake Shore Dr & North Blvd  19964\n",
      "5                      Shedd Aquarium  18247\n",
      "6                 Theater on the Lake  15830\n",
      "7               Wells St & Concord Ln  13405\n",
      "8                      Dusable Harbor  12904\n",
      "9          Indiana Ave & Roosevelt Rd  11692\n"
     ]
    }
   ],
   "source": [
    "casual_station_count = casual_df.loc[:,'start_station_name'].value_counts()\n",
    "casual_station_count = casual_station_count.nlargest(10)\n",
    "casual_station_count = casual_station_count.reset_index(name='count')\n",
    "casual_station_count = casual_station_count.rename(columns={'index': 'station'})\n",
    "\n",
    "print(casual_station_count)\n",
    "with pd.ExcelWriter('cyclistics_data.xlsx', mode='a', if_sheet_exists='replace') as writer:\n",
    "    casual_station_count.to_excel(writer, sheet_name='top_casual_start_station', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9030bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
